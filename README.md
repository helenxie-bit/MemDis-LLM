# MemDis-LLM
This project explores memory disaggregation for Large Language Model (LLM) inference, with a focus on designing and implementing a memory scheduler optimized for hybrid memory environments (local + remote). Our goal is to evaluate how disaggregated memory impacts LLM inference performance through comprehensive experiments on real hardware.

üõ†Ô∏è Note: This project is in its early stages, and implementation work is currently in progress.
